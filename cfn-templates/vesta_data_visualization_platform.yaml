
AWSTemplateFormatVersion: '2010-09-09'
Description: 'aws-elasticsearch-deployment'

Mappings:
  # Update this mapping when the lambda function rev/name is updated in staging bucket
  LambdaFunctionPackage:
     IndexDataFunction:
      Package: index_data_2a22f36825fc834d5cec7078231babcd
     DeleteDataFunction:
      Package: delete_data_fb2380282db84bee208a02c6cd4fabcd
     RetentionFunction:
      Package: retention_d98e27341497b6cadb1fd75f1c93abcd

  # Update this mapping with whitelisted indices
  WhitelistedIndices:
    All:
      Indices: amol, kokje

Parameters:

  # ElasticSearch configuration

  InstanceType:
    Description: AWS Elasticsearch Instance Type
    Type: String
    Default: t2.small.elasticsearch
    AllowedValues:
      - i3.2xlarge.elasticsearch
      - m5.4xlarge.elasticsearch
      - t3.xlarge.elasticsearch
      - i3.4xlarge.elasticsearch
      - m3.large.elasticsearch
      - r4.16xlarge.elasticsearch
      - t2.micro.elasticsearch
      - m4.large.elasticsearch
      - d2.2xlarge.elasticsearch
      - t3.micro.elasticsearch
      - m5.large.elasticsearch
      - i3.8xlarge.elasticsearch
      - i3.large.elasticsearch
      - d2.4xlarge.elasticsearch
      - t2.small.elasticsearch
      - c4.2xlarge.elasticsearch
      - t3.small.elasticsearch
      - c5.2xlarge.elasticsearch
      - c4.4xlarge.elasticsearch
      - d2.8xlarge.elasticsearch
      - c5.4xlarge.elasticsearch
      - m3.medium.elasticsearch
      - c4.8xlarge.elasticsearch
      - c4.large.elasticsearch
      - c5.xlarge.elasticsearch
      - c5.large.elasticsearch
      - c4.xlarge.elasticsearch
      - c5.9xlarge.elasticsearch
      - d2.xlarge.elasticsearch
      - t3.nano.elasticsearch
      - t3.medium.elasticsearch
      - t2.medium.elasticsearch
      - t3.2xlarge.elasticsearch
      - c5.18xlarge.elasticsearch
      - i3.xlarge
    ConstraintDescription: Must be a valid Elasticsearch instance type.

  InstanceCount:
    Description: AWS Elasticsearch Instance Count
    Type: String
    Default: '2'
    AllowedValues:
      - '2'
      - '4'
    ConstraintDescription: You must choose an even number of data nodes for a two AZ deployment

  DedicatedMasterCount:
    Description: AWS Elasticsearch Dedicated Master Node Count
    Type: String
    Default: '3'
    AllowedValues:
      - '3'
      - '5'
    ConstraintDescription: Dedicated master node count should be an odd number to avoid split-brain.

  # Cognito Authentication

  IdentityPoolArn:
    Description: AWS Cognito Identity Pool ARN
    Default: 'arn:aws:iam::697987864314:role/Cognito_myidentitypoolAuth_Role'
    Type: String
    ConstraintDescription: Must be a valid ARN

  # Lambda Function

  LambdaSourceBucket:
    Description: AWS S3 Bucket in the Region which contains the Lambda Functions
    Type: String
    Default: elasticsearch-lambda-functions
    ConstraintDescription: Must be a valid bucket name containing Lambda functions, and in the same region.

  LambdaSourceBucketPrefix:
    Description: AWS S3 Bucket Prefix containing Lambda Functions
    Type: String
    Default: ''
    ConstraintDescription: Bucket prefix that contains the lambda functions.

  # Retention Configuration

  CloudWatchLogsRetentionDays:
    Description: Retention days for CloudWatch Logs from Lambda Function Invocations
    Type: Number
    Default: '2'
    MinValue: '1'
    MaxValue: '5'
    ConstraintDescription: Must be between 1 and 5 days.

  DataRetentionDays:
    Description: Retention days for Data Source
    Type: Number
    Default: '600'
    MinValue: '200'
    MaxValue: '600'
    ConstraintDescription: Must be between 200 and 500 days.

  RetentionRate:
    Description: The rate (frequency) that determines when CloudWatch Events runs the rule that
        triggers the Retention function (in minutes).
    Default: rate(1440 minutes)
    AllowedValues:
      - rate(1440 minutes)
      - rate(2280 minutes)
      - rate(4320 minutes)
    Type: String

  # Deployment type for relevant management automation

  DeploymentType:
    Description: Stack Deployment Type. Acceptable Options are ENG or PROD
    Type: String
    Default: 'ENG'
    AllowedValues:
      - 'ENG'
      - 'PROD'
    ConstraintDescription: ENG or PROD

Resources:

  #######################################################
  ### Elasticsearch Domain
  #######################################################

  ElasticsearchDomain:
    Type: AWS::Elasticsearch::Domain
    Properties:
      DomainName: !Ref AWS::StackName
      ElasticsearchVersion: '7.1'
      ElasticsearchClusterConfig:
        DedicatedMasterEnabled: "true"
        InstanceCount: !Ref InstanceCount
        ZoneAwarenessEnabled: "true"
        InstanceType: !Ref InstanceType
        DedicatedMasterType: !Ref InstanceType
        DedicatedMasterCount: !Ref DedicatedMasterCount
      EBSOptions:
        EBSEnabled: true
        Iops: 0
        VolumeSize: 20
        VolumeType: "gp2"
      SnapshotOptions:
        AutomatedSnapshotStartHour: "0"
      AccessPolicies:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              AWS: !Ref 'IdentityPoolArn'
            Action: 'es:ESHttp*'
            Resource: !Sub 'arn:aws:es:${AWS::Region}:${AWS::AccountId}:domain/${AWS::StackName}/*'
            Condition:
              IpAddress:
                aws:SourceIp:
                  - 64.39.96.0/20
                  - 52.27.190.0/23
      AdvancedOptions:
        rest.action.multi.allow_explicit_index: "true"

  #######################################################
  ### Bucket to Store ES Data
  #######################################################

  # Note the DependsOn. This ensures that CFN does not try to create the resources in parallel, and hence fail.
  # DependsOn section will enforce a sequence thus creating the Lambda functions, permissions, etc before
  # trying to create the bucket, so that it is able to use those resources to configure event notifications.
  DataBucket:
    Type: 'AWS::S3::Bucket'
    DependsOn:
      - IndexDataLambdaInvokePermission
      - DeleteDataLambdaInvokePermission
    Properties:
      BucketName: !Ref AWS::StackName
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectCreated:*
            Function: !GetAtt 'IndexDataFunction.Arn'
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: .json
          - Event: s3:ObjectRemoved:*
            Function: !GetAtt 'DeleteDataFunction.Arn'
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: .json

  # This bucket will contain all the documents, data for which will be purged from Elasticsearch. The move to this
  # bucket will be managed using RetentionFunction Lambda
  RetentionDataBucket:
    Type: 'AWS::S3::Bucket'

  # Grants S3 bucket permission to invoke the lambda function. Need to specify the ARN of the bucket. Also, need
  # the account ID if its an AWS service.
  IndexDataLambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref IndexDataFunction
      Principal: s3.amazonaws.com
      SourceArn: !Sub 'arn:aws:s3:::${AWS::StackName}'
      SourceAccount: !Ref AWS::AccountId

  DeleteDataLambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref DeleteDataFunction
      Principal: s3.amazonaws.com
      SourceArn: !Sub 'arn:aws:s3:::${AWS::StackName}'
      SourceAccount: !Ref AWS::AccountId



#  #######################################################
#  ### Bucket which contains Lambda zips
#  #######################################################

  # Bucket that will eventually contain lambda zips used for creating lambda function
  LambdaZipsBucket:
    Type: AWS::S3::Bucket

#  #######################################################
#  ### Logic for deploying Lambda functions
#  #######################################################

  # Custom Resource: Used to copy all specified lambda zip packages in the 'Objects' list to the LambdaZipsBucket
  # Specify Versions and Objects in the same order. The object version ID is available from s3
  CopyZips:
    Type: Custom::CopyZips
    Properties:
      ServiceToken: !GetAtt 'CopyZipsFunction.Arn'
      DestBucket: !Ref 'LambdaZipsBucket'
      SourceBucket: !Ref 'LambdaSourceBucket'
      Prefix: !Ref 'LambdaSourceBucketPrefix'
      Objects:
        - !FindInMap [LambdaFunctionPackage, IndexDataFunction, Package]
        - !FindInMap [LambdaFunctionPackage, DeleteDataFunction, Package]
        - !FindInMap [LambdaFunctionPackage, RetentionFunction, Package]

  # CopyZips lambda function role
  # - basic execution role
  # - permission to get object from bucket where all lambda zips are stored
  # - permission to put/delete into the bucket which is used to create the lambda function
  CopyZipsFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub 'arn:aws:s3:::${LambdaSourceBucket}/${LambdaSourceBucketPrefix}*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                Resource:
                  - !Sub 'arn:aws:s3:::${LambdaZipsBucket}/${LambdaSourceBucketPrefix}*'


#  # Lambda function used by the Custom-Resource CopyZips to copy over the lambda functions to bucket used by stack
#  # to create the lambda functions
  CopyZipsFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Copies objects from a source S3 bucket to a destination
      Handler: index.handler
      Runtime: python2.7
      Role: !GetAtt 'CopyZipsFunctionRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import json
          import logging
          import threading
          import boto3
          import cfnresponse

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          s3 = boto3.client('s3')

          def copy_objects(source_bucket, dest_bucket, prefix, objects):
              """
              Copy specified objects from source to destination bucket
              :param source_bucket: source bucket name
              :param dest_bucket: destination bucket name
              :param prefix: source bucket prefix
              :param objects: list of objects to copy
              :return: None
              """
              for item in objects:
                  key = prefix + item
                  copy_source = {
                      'CopySource': '/{}/{}'.format(source_bucket, key),
                      'Bucket': source_bucket,
                      'Key': key
                  }
                  logger.info('copy_source: [{}]'.format(copy_source))
                  logger.info('dest_bucket: [{}]'.format(dest_bucket))
                  logger.info('key: [{}]'.format(key))
                  s3.copy_object(CopySource=copy_source, Bucket=dest_bucket, Key=key)


          def delete_objects(bucket, prefix, objects):
              """
              Delete specified s3 objects
              :param bucket: bucket name
              :param prefix: bucket prefix
              :param objects: list of object names
              :return None
              """
              objects = {'Objects': [{'Key': prefix + item} for item in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)


          def timeout_handler(event, context):
              """
              Timeout handling
              :param event: lambda function event
              :param context: lambda function context
              :return None
              """
              logger.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)


          def handler(event, context):
              """
              Lambda function handler
              :param event: lambda function event
              :param context: lambda function context
              :return None
              """
              # make sure we send a failure to CloudFormation if the function
              # is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis()
                        / 1000.00) - 0.5, timeout_handler, args=[event, context])
              timer.start()

              logger.info('Event: [{}]'.format(event))
              status = cfnresponse.SUCCESS

              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  prefix = event['ResourceProperties']['Prefix']
                  objects = event['ResourceProperties']['Objects']
                  logging.info('SourceBucket=[{}], DestinationBucket=[{}], Prefix=[{}], \
                                                        Objects=[{}]'.format(
                                                        source_bucket, dest_bucket, prefix, objects))

                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, prefix, objects)
                  else:
                      copy_objects(source_bucket, dest_bucket, prefix, objects)

              except Exception as e:
                  logger.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED

              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)

#  #######################################################
#  ### Lambda functions to be deployed
#  #######################################################

  ### IndexData - function that indexes data to ES when object is added to S3

  # Role for actual lambda functions to be deployed by the stack
  IndexDataFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: 'lambda-es-policy'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action: 'es:*'
                Resource: '*'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute


  # Lambda function deployed by the stack
  # Notice the DependsOn key pointing to our CopyZips custom resource. By default, AWS CloudFormation will attempt
  # to launch resources that are not dependent on each other in parallel, so this is required to be sure that the zips
  # have already been copied before our Lambda function is created.
  IndexDataFunction:
    DependsOn:
      - CopyZips
      - ElasticsearchDomain
    Type: AWS::Lambda::Function
    Properties:
      Description: 'Lambda function to index data to ES when object is added to S3'
      Handler: index_data.lambda_handler
      Runtime: python2.7
      Role: !GetAtt 'IndexDataFunctionRole.Arn'
      MemorySize: 3008
      Timeout: 900
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Join [ '', [ !Ref LambdaSourceBucketPrefix, !FindInMap [LambdaFunctionPackage, IndexDataFunction, Package] ] ]
      Environment:
        Variables:
          'ES_ENDPOINT_HOST': !GetAtt ElasticsearchDomain.DomainEndpoint
          'ES_ENDPOINT_PORT': '443'
          'REGION': !Sub '${AWS::Region}'

  ### DeleteData - function that deletes data from ES when object is deleted from S3

  DeleteDataFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: 'lambda-es-policy'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action: 'es:*'
                Resource: '*'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute

  DeleteDataFunction:
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: 'Lambda function to delete data from ES when object is removed from S3 bucket'
      Handler: delete_data.lambda_handler
      Runtime: python2.7
      Role: !GetAtt 'DeleteDataFunctionRole.Arn'
      Timeout: 300
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Join [ '', [ !Ref LambdaSourceBucketPrefix, !FindInMap [LambdaFunctionPackage, DeleteDataFunction, Package] ] ]
      Environment:
        Variables:
          'ES_ENDPOINT_HOST': !GetAtt ElasticsearchDomain.DomainEndpoint
          'ES_ENDPOINT_PORT': '443'
          'REGION': !Sub '${AWS::Region}'

  ### Retention - Function to manage data retention

  RetentionFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: 'lambda-s3-logs-policy'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action: 'logs:*'
                Resource: '*'
              - Effect: 'Allow'
                Action: 's3:*'
                Resource: '*'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute

  RetentionFunction:
    DependsOn:
      - CopyZips
      - RetentionDataBucket
    Type: AWS::Lambda::Function
    Properties:
      Description: 'Lambda function to manage retention'
      Handler: retention.lambda_handler
      Runtime: python2.7
      MemorySize: 3008
      Timeout: 900
      Role: !GetAtt 'RetentionFunctionRole.Arn'
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Join [ '', [ !Ref LambdaSourceBucketPrefix, !FindInMap [LambdaFunctionPackage, RetentionFunction, Package] ] ]
      Environment:
        Variables:
          'CLOUDWATCH_LOGS_RETENTION_DAYS': '2'
          'S3_RETENTION_DAYS': !Ref DataRetentionDays
          'S3_ENG_RETENTION_DAYS': '30'
          'S3_RETENTION_BUCKET_NAME': !Ref RetentionDataBucket
          'DATA_BUCKET_NAME': !Ref DataBucket
          'WHITELISTED_INDICES': !FindInMap [WhitelistedIndices, All, Indices]
          'DEPLOYMENT': !Ref DeploymentType

  # Scheduling Mechanism using Cloudwatch rules to run RetentionFunction at periodic intervals

  RetentionFunctionSchedule:
    Type: 'AWS::Events::Rule'
    DependsOn:
      - RetentionFunction
    Properties:
      Description: Schedule at which the Retention Lambda function runs
      ScheduleExpression: !Ref RetentionRate
      State: ENABLED
      Targets:
        - Arn: !Sub ${RetentionFunction.Arn}
          Id: RetentionFunctionSchedule

  RetentionFunctionSchedulePermission:
    Type: 'AWS::Lambda::Permission'
    DependsOn:
      - RetentionFunction
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Sub ${RetentionFunction.Arn}
      Principal: 'events.amazonaws.com'
      SourceArn: !Sub ${RetentionFunctionSchedule.Arn}
